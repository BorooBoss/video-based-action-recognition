{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Instructions — VLM Anomaly Analyzer</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="{% static 'css/style.css' %}">
    <style>
        .perf-seconds {
            display: inline-block;
            font-variant-numeric: tabular-nums;
            font-size: 0.82rem;
            font-weight: 600;
            color: #2d3a55;
            background: #f0f4ff;
            border: 1px solid #d0d9f0;
            border-radius: 4px;
            padding: 2px 8px;
            letter-spacing: 0.01em;
            min-width: 52px;
            text-align: center;
        }
        .perf-na {
            display: inline-block;
            font-size: 0.78rem;
            color: #aaa;
            font-style: italic;
        }

        /* Carousel overlay */
        #carousel-overlay {
            display: none;
            position: absolute;
            inset: 0;
            background: white;
            border-radius: 8px;
            z-index: 5;
            align-items: center;
            justify-content: center;
        }
        #carousel-overlay.active {
            display: flex;
        }
        #carousel-overlay img {
            width: 100%;
            height: 100%;
            object-fit: contain;
            border-radius: 6px;
        }
        .carousel-nav-btn {
            position: absolute;
            top: 50%;
            transform: translateY(-50%);
            background: #0a6cff;
            border: none;
            border-radius: 50%;
            width: 30px;
            height: 30px;
            color: white;
            cursor: pointer;
            font-size: 0.8rem;
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: 0 2px 8px rgba(10,108,255,0.35);
            z-index: 10;
            transition: background 0.2s, transform 0.15s;
        }
        .carousel-nav-btn:hover {
            background: #0050cc;
            transform: translateY(-50%) scale(1.1);
        }
        .carousel-nav-btn.prev { left: -15px; }
        .carousel-nav-btn.next { right: -15px; }

        /* Close button */
        #carousel-close {
            position: absolute;
            top: 6px;
            right: 6px;
            background: rgba(10,108,255,0.12);
            border: none;
            border-radius: 50%;
            width: 26px;
            height: 26px;
            color: #0a6cff;
            cursor: pointer;
            font-size: 0.75rem;
            display: flex;
            align-items: center;
            justify-content: center;
            z-index: 11;
            transition: background 0.2s;
        }
        #carousel-close:hover { background: rgba(10,108,255,0.22); }

        /* The wrapper card needs relative positioning */
        .how-it-works-inner {
            position: relative;
        }

        /* Step images inside how-to-use block */
        .step-image-block {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin-bottom: 1.5rem;
        }
        .step-image-block img {
            max-width: 100%;
            border-radius: 10px;
            border: 1px solid rgba(10, 108, 255, 0.15);
            box-shadow: 0 4px 16px rgba(9, 30, 66, 0.1);
            margin-bottom: 0.85rem;
        }

        /* Cards below row 1 match full width of top row */
        .centered-card-col .instructions-card {
            width: 100%;
        }

        /* Push hero content to bottom while keeping hero height */
        .hero.is-brand .hero-body {
            display: flex;
            align-items: flex-end;
            padding-top: 7rem;
            padding-bottom: 2.5rem;
            min-height: 220px;
        }
    </style>
</head>
<body>

<section class="hero is-brand">
    <div class="hero-body">
        <div class="container">
            <div class="columns is-vcentered">
                <div class="column is-8">
                    <h1 class="title is-2">Instructions</h1>
                    <h2 class="subtitle is-5">How to use the VLM Anomaly Analyzer</h2>
                </div>
                <div class="column is-4 has-text-right">
                    <a class="navbar-instructions" href="/recognizer/">
                        <i class="fas fa-arrow-left" style="margin-right:0.4rem;"></i>Back to App
                    </a>
                </div>
            </div>
        </div>
    </div>
</section>

<main class="section">
    <div class="container">

        <!-- ROW 1: How does this application work? + Supported File Formats (unchanged) -->
        <div class="columns is-equal-height" style="align-items: stretch;">
            <div class="column is-8" style="display:flex; flex-direction:column;">
                <div class="instructions-card" style="flex:1; margin-bottom:0;">

                    <div class="how-it-works-inner">

                        <!-- === CAROUSEL OVERLAY (hidden by default) === -->
                        <div id="carousel-overlay">
                            <img id="carousel-img" src="" alt="Prompt illustration">
                        </div>
                        <!-- === END OVERLAY === -->

                        <div class="instructions-section-header">
                            <div class="instructions-section-title">How does this application work?</div>
                        </div>
                        <p style="color:#2d3a55; font-size:0.95rem; line-height:1.7;">
                            The goal of this project was to develop an application capable of detecting illegal activities or anomalies in CCTV camera footage.
                            To achieve this, we used <strong> Vision Language Models (VLMs) </strong>. These models are designed to process two types of inputs -
                            images and text. By leveraging these multimodal capabilities, the system support various types of tasks (prompts):
                        </p>

                        <div style="display:flex; gap:0.75rem; flex-wrap:wrap; margin-top:1rem; position:relative;">

                            <button class="carousel-nav-btn prev" style="left:-15px; top:50%; position:absolute;" onclick="carouselNav(-1)">
                                <i class="fas fa-chevron-left"></i>
                            </button>

                            <div class="tip-box" style="flex:1; min-width:180px;">
                                <strong><i class="fas fa-align-left" style="margin-right:0.3rem;"></i>CAPTION</strong><br>
                                Generates text description visible from the image
                            </div>
                            <div class="tip-box" style="flex:1; min-width:180px;">
                                <strong><i class="fas fa-question-circle" style="margin-right:0.3rem;"></i>VQA</strong><br>
                                Provides answers to user questions based on the uploaded image
                            </div>
                            <div class="tip-box" style="flex:1; min-width:180px;">
                                <strong><i class="fas fa-vector-square" style="margin-right:0.3rem;"></i>DETECT</strong><br>
                                Returns co-ordinates of objects, allowing bounding boxes to be drawn around them
                            </div>

                            <button class="carousel-nav-btn next" style="right:-15px; top:50%; position:absolute;" onclick="carouselNav(1)">
                                <i class="fas fa-chevron-right"></i>
                            </button>

                        </div>

                    </div><!-- end how-it-works-inner -->
                </div>
            </div>

            <div class="column is-4" style="display:flex; flex-direction:column;">
                <div class="instructions-card" style="flex:1; margin-bottom:0;">
                    <div class="instructions-section-header">
                        <div class="instructions-section-title">Supported File Formats</div>
                    </div>
                    <p style="font-size:0.88rem; color:#2d3a55; margin-bottom:0.75rem;"><strong>Images:</strong></p>
                    <div style="display:flex; gap:0.4rem; flex-wrap:wrap; margin-bottom:1rem;">
                        <span class="tag is-brand">JPG</span>
                        <span class="tag is-brand">PNG</span>
                    </div>
                    <p style="font-size:0.88rem; color:#2d3a55; margin-bottom:0.75rem;"><strong>Videos:</strong></p>
                    <div style="display:flex; gap:0.4rem; flex-wrap:wrap;">
                        <span class="tag is-brand-dark">MP4</span>
                        <span class="tag is-brand-dark">AVI <small style="margin-left:3px;"></small></span>
                        <span class="tag is-brand-dark">MPEG <small style="margin-left:3px;"></small></span>
                    </div>
                    <div class="tip-box mt-4">
                        <strong><i class="fas fa-film" style="margin-right:0.3rem;"></i>Video conversion : </strong>
                        AVI and MPEG videos are automatically converted to MP4
                    </div>
                </div>
            </div>
        </div>

        <!-- ROW 2: How to use — matches width of top row -->
        <div class="columns">
            <div class="column is-12 centered-card-col">
                <div class="instructions-card" style="width:100%;">
                    <div class="instructions-section-header">
                        <div class="instructions-section-title">How to use the application</div>
                    </div>

                    <div class="step-image-block">
                        <div class="step-row" style="width:100%;">
                            <span class="step-number">1</span>
                            <span>We are able to pick from <strong>6 different standard models</strong> and <strong>2 fine-tuned models</strong>, trained on annotated crime dataset.
                                Each model supports different types of prompts which can be run.</span>
                        </div>
                        <img src="{% static 'images/preview1.png' %}" alt="Step 1 - Select model">
                    </div>

                    <div class="step-image-block">
                        <div class="step-row" style="width:100%;">
                            <span class="step-number">2</span>
                            <span>Check one or more <strong>prompt types</strong> you want to run. You can combine multiple prompts in a single request.</span>
                        </div>
                        <img src="{% static 'images/preview2.png' %}" alt="Step 2 - Select prompts">
                    </div>

                    <div class="step-image-block">
                        <div class="step-row" style="width:100%;">
                            <span class="step-number">3</span>
                            <span><strong>Upload</strong> an image (JPG, PNG) or video (MP4, AVI, MPEG) using the file picker.</span>
                        </div>
                        <img src="{% static 'images/preview3.png' %}" alt="Step 3 - Upload file">
                    </div>

                    <div class="step-image-block" style="margin-bottom:1rem;">
                        <div class="step-row" style="width:100%;">
                            <span class="step-number">4</span>
                            <span>Click <strong>Analyze</strong> and wait for the results to appear in the Output box.</span>
                        </div>
                        <img src="{% static 'images/preview4.png' %}" alt="Step 4 - Analyze">
                    </div>

                    <!-- Processing images/videos tip (restored after steps) -->
                    <div class="tip-box">
                        <strong><i class="fas fa-film" style="margin-right:0.3rem;"></i>Processing images/videos : </strong>
                        The user can choose whether to upload an image or a video as input. When an image is uploaded, the model processes the image directly and generates results based on the selected prompt. <br>
                        If we upload video, the video is first split into individual frames. Each frame is then processed independently by selected model, result is generated for every single frame.
                    </div>
                </div>
            </div>
        </div>

        <!-- ROW 3: Types of prompts -->
        <div class="columns">
            <div class="column is-12 centered-card-col">
                <div class="instructions-card" style="width:100%;">
                    <div class="instructions-section-header">
                        <div class="instructions-section-title">Types of prompts</div>
                    </div>

                    <p style="color:#2d3a55; font-size:0.92rem; margin-bottom:1rem;">
                        For <strong>CAPTION</strong> prompts, users can choose between different levels of detail.
                        <br> &nbsp; - Simple caption is usually short, results may contain hallucinations.
                        <br> &nbsp; - Standard caption generates longer and more accurate descriptions.
                        <br> &nbsp; - Detailed caption returns the most accurate results.
                    </p>
                    <p style="color:#2d3a55; font-size:0.92rem; margin-bottom:1rem;">
                        For <strong>VQA</strong> prompts, users can write custom questions they want the model to answer.
                        Questions should be ended with a <code>?</code> so the model
                        correctly identifies the end of the sentence. Multiple questions can be submitted at once,
                        they have to be separated with <code>?</code> after each question.
                    </p>
                    <p style="color:#2d3a55; font-size:0.92rem; margin-bottom:0;">
                        For <strong>DETECT</strong> prompts, the behavior depends on the selected model.
                        <br> &nbsp; - Florence2 models detects all visible objects, meaning the user cannot specify what objects to detect.
                        <br> &nbsp; - PaliGemma2 models requires you to specify which objects to search for. To detect multiple objects, use <code>;</code> between them.
                    </p>

                    <div class="tip-box" style="margin-top:1rem;">
                        <strong><i class="fas fa-lightbulb" style="margin-right:0.3rem;"></i>Tip:</strong>
                        When using <strong>VQA</strong> or <strong>DETECT</strong> on a video, a colored timeline appears below the frame slider. Green segments indicate frames where the answer was positive (detected), red where it was not.
                    </div>
                </div>
            </div>
        </div>

        <!-- ROW 4: Model Table -->
        <div class="columns">
            <div class="column is-12 centered-card-col">
                <div class="instructions-card" style="width:100%;">
                    <div class="instructions-section-header">
                        <div class="instructions-section-title">Available Models & Supported Prompts</div>
                    </div>

                    <div class="table-container">
                        <table class="table is-fullwidth is-bordered model-table">
                            <thead>
                            <tr>
                                <th style="color: white !important;">Model</th>
                                <th style="color: white !important;">CAPTION</th>
                                <th style="color: white !important;">VQA</th>
                                <th style="color: white !important;">DETECT</th>
                                <th style="color: white !important;">Notes</th>
                            </tr>
                            </thead>
                            <tbody>
                            <tr>
                                <td><strong>Paligemma2-3b-pt-224</strong></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td>Pre-trained model</td>
                            </tr>
                            <tr>
                                <td><strong>Paligemma2-3b-mix-224</strong></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td>Fine-tuned model on non-crime datasets</td>
                            </tr>
                            <tr>
                                <td><strong>Florence-2-large</strong></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td><span class="tag is-danger is-light">NO</span></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td>Pre-trained model</td>
                            </tr>
                            <tr>
                                <td><strong>Florence-2-large-ft</strong></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td>Fine-tuned model for VQA support</td>
                            </tr>
                            <tr>
                                <td><strong>Qwen3-VL-2B-Instruct</strong></td>
                                <td><span class="tag is-danger is-light">NO</span></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td><span class="tag is-danger is-light">NO</span></td>
                                <td>Pre-trained model</td>
                            </tr>
                            <tr>
                                <td><strong>InternVL3.5-2B</strong></td>
                                <td><span class="tag is-danger is-light">NO</span></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td><span class="tag is-danger is-light">NO</span></td>
                                <td>Pre-trained model</td>
                            </tr>
                            <tr>
                                <td><strong>paligemma2_weapon_detection</strong></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td><span class="tag is-success is-light">YES</span></td>
                                <td>Fine-tuned on annotated crime dataset</td>
                            </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </div>

        <!-- ROW 5: Performance & Speed -->
        <div class="columns">
            <div class="column is-12 centered-card-col">
                <div class="instructions-card" style="width:100%;">
                    <div class="instructions-section-header">
                        <div class="instructions-section-title">Performance & Speed</div>
                    </div>
                    <p style="font-size:0.88rem; color:#2d3a55; margin-bottom:0.85rem;">
                        The following performance table shows expectations for <strong>already loaded models </strong>.
                        Launching model for the first time means loading model into cache memory.
                        if another model is already active, it must be unloaded first.
                        This <strong>caching process may add a few seconds</strong> to the benchmarks. <br>
                        Time values are tested on <strong>FULL-HD images and videos </strong>, if we upload files with higher resolution, results might be delayed. Upload limit is <strong> 200MB</strong>.
                    </p>
                    <div class="table-container">
                        <table class="table is-fullwidth is-bordered model-table" style="font-size:0.83rem;">
                            <thead>
                            <tr>
                                <th style="color: white !important; min-width:140px;">Model</th>
                                <th style="color: white !important; text-align:center;">Image with 1 task</th>
                                <th style="color: white !important; text-align:center;">Image with 2 tasks</th>
                                <th style="color: white !important; text-align:center;">10s Video with 1 task</th>
                                <th style="color: white !important; text-align:center;">10s Video with 2 tasks</th>
                            </tr>
                            </thead>
                            <tbody>
                            <tr>
                                <td><strong>PaliGemma2</strong></td>
                                <td style="text-align:center;"><span class="perf-seconds">&lt;1s</span></td>
                                <td style="text-align:center;"><span class="perf-seconds">&lt;1s</span></td>
                                <td style="text-align:center;"><span class="perf-seconds">6s</span></td>
                                <td style="text-align:center;"><span class="perf-seconds">6s</span></td>
                            </tr>
                            <tr>
                                <td><strong>Florence2</strong></td>
                                <td style="text-align:center;"><span class="perf-seconds">&lt;1s</span></td>
                                <td style="text-align:center;"><span class="perf-seconds">&lt;1s</span></td>
                                <td style="text-align:center;"><span class="perf-seconds">2s</span></td>
                                <td style="text-align:center;"><span class="perf-seconds">3s</span></td>
                            </tr>
                            <tr>
                                <td><strong>Qwen3</strong></td>
                                <td style="text-align:center;"><span class="perf-seconds">2s</span></td>
                                <td style="text-align:center;"><span class="perf-seconds">3s</span></td>
                                <td style="text-align:center;"><span class="perf-seconds">22s</span></td>
                                <td style="text-align:center;"><span class="perf-seconds">37s</span></td>
                            </tr>
                            <tr>
                                <td><strong>InternVL3.5</strong></td>
                                <td style="text-align:center;"><span class="perf-seconds">1s</span></td>
                                <td style="text-align:center;"><span class="perf-seconds">2s</span></td>
                                <td style="text-align:center;"><span class="perf-seconds">22s</span></td>
                                <td style="text-align:center;"><span class="perf-seconds">22s</span></td>
                            </tr>
                            </tbody>
                        </table>
                    </div>
                    <div class="tip-box" style="margin-top:0.75rem;">
                        <strong><i class="fas fa-terminal" style="margin-right:0.3rem;"></i>Console Log</strong> at the bottom of the app shows whether the server is
                        waiting for a response or if the model has already finished processing.
                    </div>
                </div>
            </div>
        </div>

    </div>
</main>

<footer class="footer">
    <div class="content has-text-centered">
        <p class="is-size-7">© 2026 VLM Activity Analyzer</p>
    </div>
</footer>

<script>
    const carouselImages = [
        "{% static 'images/idea_caption.png' %}",
        "{% static 'images/idea_vqa.png' %}",
        "{% static 'images/idea_detect.png' %}"
    ];

    let carouselIndex = -1;
    const overlay  = document.getElementById('carousel-overlay');
    const img      = document.getElementById('carousel-img');

    function carouselNav(dir) {
        carouselIndex += dir;

        if (carouselIndex < 0) {
            carouselIndex = -1;
            overlay.classList.remove("active");
            return;
        }

        if (carouselIndex >= carouselImages.length) {
            carouselIndex = -1;
            overlay.classList.remove("active");
            return;
        }

        img.src = carouselImages[carouselIndex];
        overlay.classList.add("active");
    }
</script>
</body>
</html>